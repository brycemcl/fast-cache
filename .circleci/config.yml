version: 2.1
commands:
  save_cache_zstd:
    parameters:
      paths:
        description: 'List of directories which should be added to the cache'
        type: string
        default: '"."'
      key:
        description: 'Unique identifier for this cache'
        type: string
      displayName:
        description: 'Title of the step to be shown in the CircleCI UI'
        type: string
        default: 'Saving Cache'
      when:
        description: 'Specify when to enable or disable the step. Takes the following values: always, on_success, on_fail (default: on_success)'
        type: string
        default: 'on_success'
    steps:
      - run:
          name: << parameters.displayName >>
          when: << parameters.when >>
          command: |
            #!/bin/bash
            echo "Uploading << parameters.paths >> to << parameters.key >>"
            set -e
            start=$(date +%s)
            tar -cP << parameters.paths >> |
              zstd -2 --long --threads=4 - |
              rclone rcat \
                --buffer-size=16Mi \
                --checkers=16 \
                --fast-list \
                --ignore-checksum \
                --streaming-upload-cutoff=100Ki \
                --transfers=40 \
                --use-mmap \
                "cache:fast-cache/<< parameters.key >>.tar.zstd"
            end=$(date +%s)
            runtime=$((end - start))
            echo "Upload: $runtime seconds"
            echo "cache:fast-cache/<< parameters.key >>.tar.zstd"
  restore_cache_zstd:
    parameters:
      keys:
        description: 'List of cache keys to lookup for a cache to restore. Only first existing key will be restored.'
        type: string
      displayName:
        description: 'Title of the step to be shown in the CircleCI UI'
        type: string
        default: 'Restoring Cache'
    steps:
      - run:
          name: << parameters.displayName >>
          command: |
            #!/bin/bash

            find_objects_in_bucket() {
              # Loop through all arguments passed to the function
              for param in "$@"; do
                # Try to find an exact match by adding the .tar.zstd prefix
                exact_match=$(rclone lsjson --fast-list --files-only cache:fast-cache/${param}.tar.zstd | jq -e '.[].Path')

                # If an exact match is found
                if [ -n "$exact_match" ]; then
                  echo "Exact match found: $exact_match"
                  process_objects "$exact_match"
                  return
                else
                  # Else, find a prefix match sorted by ModTime
                  prefix_match=$(rclone lsjson --fast-list --files-only cache:fast-cache/ --include "${param}*" | jq 'sort_by(.ModTime) | last | .Path')

                  if [ -n "$prefix_match" ]; then
                    echo "Prefix match found: $prefix_match"
                    process_objects "$prefix_match"
                    return
                  else
                    echo "No match found for $param"
                  fi
                fi
              done
            }

            process_objects() {
              local object=$1
              echo "Processing $object"
              rclone lsjson --fast-list "cache:fast-cache/$object"
              rclone cat \
                --buffer-size=16Mi \
                --checkers=16 \
                --fast-list \
                --ignore-checksum \
                --transfers=40 \
                --use-mmap \
                "cache:fast-cache/$object" |
                zstd -d - |
                tar -xP --skip-old-files -
            }

            # Call the function with all script arguments
            find_objects_in_bucket "v1-"

jobs:
  zstd:
    resource_class: 'small'
    # working_directory: /mnt/ramdisk
    docker:
      - image: node:18-slim
    steps:
      - run: apt-get update && apt-get install -y git openssh-client
      - checkout
      # - restore_cache:
      #     keys:
      #       - v1-
      - run: apt-get install -y tar zstd rclone jq
      - run: rclone config create cache "google cloud storage" location=us-east1 bucket_policy_only=true env_auth=true
      # - save_cache_zstd:
      #     key: 'v1-<< pipeline.git.revision >>'
      #     paths: 'node_modules/'
      - restore_cache_zstd:
          keys: 'v1-<< pipeline.git.revision >>'
  circleci:
    resource_class: 'arm.large'
    # working_directory: /mnt/ramdisk
    docker:
      - image: node:18-slim
    steps:
      - run: npm install pnpm -g
      - run: apt-get update && apt-get install -y git openssh-client
      - checkout
      - run: pnpm install
      - run: pnpm install --ignore-scripts bloater
      # - run: pnpm run start:createData
      - save_cache:
          key: v1-{{ .Environment.CIRCLE_SHA1 }}
          paths:
            - node_modules/
      - run: mv node_modules uploads.old
      - restore_cache:
          keys:
            - v1-

workflows:
  comparison:
    jobs:
      # - zstd:
      #     requires:
      #       - circleci
      - zstd
      # - circleci
